# -*- coding: utf-8 -*-
"""Mudit_Singhal(PGI18CS026).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NdIxiSBuGlIuZY-o6D-dBXFVyprw8qDl
"""

import pandas as pd
import numpy as np
from mlxtend.frequent_patterns import apriori, association_rules
import matplotlib.pyplot as plt

from google.colab import files
uploaded = files.upload()

dataset = pd.read_csv('Apriori2 dataset.csv')
dataset.head()

print(dataset)

print(dataset.shape)

dataset.info()

types = dataset.dtypes
print(types)

items = (dataset['Item(s)'].unique())
items

it = (dataset['Item 1'].unique())
it

dataset.isnull().sum()

transactions = []
for i in range(0, 9835):
    transactions.append([str(dataset.values[i,j]) for j in range(0, 33)])
transactions

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder

te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)

te_ary

df = pd.DataFrame(te_ary, columns=te.columns_)
print(df)

df=df.drop(['nan'], axis = 1)

print(df)

freq_items = apriori(df, min_support=0.5, use_colnames=True)
freq_items

rules = association_rules(freq_items, metric="confidence", min_threshold=0.5)
rules

list(rules)

print(len(rules))

freq_items['length'] = freq_items['itemsets'].apply(lambda x: len(x))
freq_items

freq_items[(freq_items['support'] >= 0.5)]

plt.scatter(rules['support'], rules['confidence'], alpha=0.5)
plt.xlabel('support')
plt.ylabel('confidence')
plt.title('Support vs Confidence')
plt.show()

plt.scatter(rules['support'], rules['lift'], alpha=0.5)
plt.xlabel('support')
plt.ylabel('lift')
plt.title('Support vs lift')
plt.show()

from google.colab import drive
drive.mount('/content/drive')

import pickle 
print("[INFO] Saving model...")
# Save the trained model as a pickle string. 
saved_model=pickle.dump(freq_items,open('/content/drive/My Drive/ML/aprioriexample.pkl', 'wb'))

model = pickle.load(open('/content/drive/My Drive/ML/aprioriexample.pkl','rb'))

!pip install streamlit

from google.colab import drive
drive.mount('/content/drive')

!pip install pyngrok

!ngrok authtoken 1oEm0wopEJyjrT38ULluwUKK5fq_7ai4ZocZJ2YuFuoiJfoMh

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st 
# from PIL import Image
# import pickle
# import numpy as np
# import matplotlib.pyplot as plt
# import pandas as pd
# from mlxtend.frequent_patterns import apriori, association_rules
# st.set_option('deprecation.showfileUploaderEncoding', False)
# def find_associatio_rule(support):
#   # Load the pickled model
#   model = pickle.load(open('/content/drive/My Drive/ML/aprioriexample.pkl','rb'))     
#   if uploaded_file is not None:
#     dataset= pd.read_csv(uploaded_file)
#   else:
#     dataset= pd.read_csv('/content/drive/My Drive/ML/dataset.csv')
# 
#   #Create list 
#   transactions = []
#   for i in range(0, 315):
#     transactions.append([str(dataset.values[i,j]) for j in range(0, 7)])
# 
#   from mlxtend.preprocessing import TransactionEncoder
#   te = TransactionEncoder()
#   te_ary = te.fit(transactions).transform(transactions)
#   df = pd.DataFrame(te_ary, columns=te.columns_)
#   freq_items = apriori(df, min_support=support, use_colnames=True)
#   rules = association_rules(freq_items, metric="confidence", min_threshold=0.6)
#   return rules
# def find_frequent_items(support):
#   # Load the pickled model
#   model = pickle.load(open('/content/drive/My Drive/ML/aprioriexample.pkl','rb'))     
#   if uploaded_file is not None:
#     dataset= pd.read_csv(uploaded_file)
#   else:
#     dataset= pd.read_csv('/content/drive/My Drive/ML/dataset.csv')
#   #Create list 
#   transactions = []
#   for i in range(0, 315):
#     transactions.append([str(dataset.values[i,j]) for j in range(0, 7)])
# 
#   from mlxtend.preprocessing import TransactionEncoder
#   te = TransactionEncoder()
#   te_ary = te.fit(transactions).transform(transactions)
#   df = pd.DataFrame(te_ary, columns=te.columns_)
#   freq_items = apriori(df, min_support=support, use_colnames=True)
#   rules = association_rules(freq_items, metric="confidence", min_threshold=0.6)
#   
#   return freq_items
# html_temp = """
#    <div class="" style="background-color:blue;" >
#    <div class="clearfix">           
#    <div class="col-md-12">
#    <center><p style="font-size:40px;color:white;margin-top:10px;">Poornima Institute of Engineering & Technology</p></center> 
#    <center><p style="font-size:30px;color:white;margin-top:10px;">Department of Computer Engineering</p></center> 
#    <center><p style="font-size:25px;color:white;margin-top:10px;"Machine Learning Lab Experiment</p></center> 
#    </div>
#    </div>
#    </div>
#    """
# st.markdown(html_temp,unsafe_allow_html=True)
# st.header("Identification of items Purchased together ")
#   
# uploaded_file = st.file_uploader("Upload dataset", help='Please upload Apriori2 dataset.csv otherwise leave  blank') 
# support = st.number_input('Insert a minimum suppport to find association rule ',0,1)
# 
#   
# if st.button("Association Rule"):
#   rules=find_associatio_rule(support)
#   st.success('Apriori has found Following rules {}'.format(rules))
# if st.button("Frequent Items"):
#   frequent_items=find_frequent_items(support)
#   st.success('Apriori has found Frequent itemsets {}'.format(frequent_items))      
# if st.button("About"):
#   st.subheader("Developed by Mudit Singhal")
#   st.subheader("PGI18CS026")
# html_temp = """
#    <div class="" style="background-color:orange;" >
#    <div class="clearfix">           
#    <div class="col-md-12">
#    <center><p style="font-size:20px;color:white;margin-top:10px;">Machine learning Experiment No. 9</p></center> 
#    </div>
#    </div>
#    </div>
#    """
# st.markdown(html_temp,unsafe_allow_html=True)

!nohup streamlit run  app.py &

from pyngrok import ngrok
url=ngrok.connect(port='8050')
url

!streamlit run --server.port 80 app.py

